{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “火炬上的深度学习\"第一次大作业\n",
    "\n",
    "在这个作业中，你需要半独立地利用人工神经网络搭建一个手写数字识别器\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"简单的 LeNet-5类型的卷积神经网络模型，MNIST例子.\n",
    "\"\"\"\n",
    "\n",
    "#所有依赖包\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#定义一系列常数\n",
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/' #图像数据如果没下载，可以从这个地址下载\n",
    "WORK_DIRECTORY = 'data' #存储的路径名\n",
    "IMAGE_SIZE = 28 #每张图片的大小尺寸\n",
    "NUM_CHANNELS = 1  #每张图片的通道数\n",
    "PIXEL_DEPTH = 255 #像素的深度0-255\n",
    "NUM_LABELS = 10 #手写数字，一共十种\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "CAN_GPU=torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取MINST图形文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#下载图像文件，如果文件已经存在，那么就不下载。\n",
    "def maybe_download(filename):\n",
    "    \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "    if not os.path.isdir(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        size = os.path.getsize(filepath)\n",
    "        print('Successfully downloaded', filename, size, 'bytes.')\n",
    "    return filepath\n",
    "# Get the data.\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    # filename: 文件存放的路径，num_images: 读入的图片个数\n",
    "    \"\"\"将图像解压缩展开，读入成一个4维的张量： [image index（图像的编码）, y（纵坐标）, x（横坐标）, channels（通道）].\n",
    "    我们将数组中的数值范围从原来的[0, 255]降低到了[-0.5, 0.5]范围内\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"将label的数据文件解压缩，并将label读成64位的整数\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels\n",
    "\n",
    "# 将数据解压缩并存储到数组中，60000张图片，60000个label，测试集中有10000张图片\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_X = train_data.reshape(len(train_data), -1)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "train_Y = train_labels\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_X = test_data.reshape(len(test_data), -1)\n",
    "\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "test_Y = test_labels\n",
    "# train_X.shape, train_Y.shape\n",
    "\n",
    "# train_X, train_Y 中分别存储的是向量化的训练数据与标签\n",
    "# test_X, test_Y 中分别存储的是向量化的测试数据与标签\n",
    "# train_X的维度是60000个样本，784个分量的图像向量\n",
    "# test_X的维度是10000个样本，784个分量的图像向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在这里写下你自己的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一步：定义神经网络，提示，可以使用简单的torch.nn.SequentialModel\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 提示：需要考虑好网络有几层，每一层有多少个节点\n",
    "net = torch.nn.Sequential(\n",
    "   torch.nn.Linear(784, 150),\n",
    "   torch.nn.Sigmoid(),\n",
    "   torch.nn.Linear(150, 30),\n",
    "   torch.nn.Sigmoid(),\n",
    "   torch.nn.Linear(30, 10),\n",
    ")\n",
    "# imgIdx=0\n",
    "# plt.imshow(train_data[imgIdx,0,:])\n",
    "# train_Y[imgIdx]\n",
    "# 问题：如果要增加新的神经网络层怎么办？\n",
    "\n",
    "if CAN_GPU:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二步：构造损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三步：开始训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，labels是数据之中的正确答案\"\"\"\n",
    "    predictions = np.argmax(predictions, 1)\n",
    "    return 100.0 - (100.0 * np.sum( predictions == labels) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age:0\tER:83.4299484719261\tLoss:2.2828428745269775\n",
      "Age:50\tER:2.650808457711443\tLoss:0.09549743682146072\n",
      "Age:100\tER:1.0133484363894811\tLoss:0.04057461768388748\n",
      "Age:150\tER:0.2953980099502488\tLoss:0.019148457795381546\n",
      "Age:200\tER:0.07051794598436391\tLoss:0.009640747681260109\n",
      "Age:250\tER:0.02221037668798864\tLoss:0.0054772961884737015\n"
     ]
    }
   ],
   "source": [
    "# 提示：有两重循环，最外面层是多少次的训练，里层为对数据批次（batch）的循环\n",
    "\n",
    "train_errors = []\n",
    "train_losses = []\n",
    "# 神经网络训练循环\n",
    "batch_size = 128\n",
    "for i in range(1000):\n",
    "    # 每128个样本点被划分为一个撮，在循环的时候一撮一撮地读取\n",
    "    batch_loss = []\n",
    "    batch_error = []\n",
    "    # start和end分别是提取一个batch数据的起始和终止下标\n",
    "    for start in range(0, len(train_X), batch_size):\n",
    "        end = start + batch_size if start + batch_size < len(train_X) else len(train_X)\n",
    "        if CAN_GPU:\n",
    "            #从训练数据train_X中提取数据\n",
    "            xx = Variable(torch.FloatTensor(train_X[start:end])).cuda() \n",
    "            #从训练数据train_Y中提取标签，注意标签数据为整数，因此相应的tensor也要为long\n",
    "            yy = Variable(torch.LongTensor(train_Y[start:end])).cuda()  \n",
    "        else:\n",
    "            xx = Variable(torch.FloatTensor(train_X[start:end]))\n",
    "            yy = Variable(torch.LongTensor(train_Y[start:end]))\n",
    "            \n",
    "        \n",
    "        predict = net(xx) #用神经网络进行预测\n",
    "        \n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        loss = cost(predict, yy) #计算损失函数（交叉熵）\n",
    "        loss.backward() #开始反向传播\n",
    "        optimizer.step() #开始更新梯度\n",
    "        \n",
    "        if CAN_GPU:\n",
    "            bloss = loss.data.cpu().numpy()\n",
    "            berror = error_rate(predict.data.cpu().numpy(),yy.data.cpu().numpy())\n",
    "        else:\n",
    "            bloss = loss.data.numpy()\n",
    "            berror = error_rate(predict.data.numpy(),yy.data.numpy())\n",
    "        batch_loss.append(bloss)    \n",
    "        batch_error.append(berror)\n",
    "    \n",
    "    # 每隔100步输出一下损失值（loss）\n",
    "    if i % 50==0:\n",
    "        train_losses.append(np.mean(batch_loss))\n",
    "        train_errors.append(np.mean(batch_error))\n",
    "        print(\"Age:{0}\\tER:{1}\\tLoss:{2}\".format(i, train_errors[-1], train_losses[-1]))\n",
    "        \n",
    "    if (len(train_errors) > 2) and (train_errors[-2] - train_errors[-1] < 0.05):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 请在这里写下你自己的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc78979d5f8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VPW5+PHPM5ONEHYCwyr7lrApomJRcGmCS9W64I7W\n1nKv1fJ7WRW9anu99/bW22rdtbYVd0FR1CqbIggqLoCAYQeJGiUgAQIEsk2e3x8zGUKYJEPImTOZ\ned6v13nlnO/Zni+j88z5fs/5HlFVjDHGGACP2wEYY4yJHZYUjDHGhFhSMMYYE2JJwRhjTIglBWOM\nMSGWFIwxxoRYUjDGGBNiScEYY0yIJQVjjDEhSW4HcLQ6duyovXr1cjsMY4xpVpYvX75TVTMb2q7Z\nJYVevXqxbNkyt8MwxphmRUS+iWQ7az4yxhgTYknBGGNMiCUFY4wxIc2uT8EY466KigoKCgooLS11\nOxQTRlpaGt27dyc5OblR+1tSMMYclYKCAlq1akWvXr0QEbfDMTWoKkVFRRQUFNC7d+9GHcOaj4wx\nR6W0tJQOHTpYQohBIkKHDh2O6SrOkoIx5qhZQohdx/rZJExS2LR9H//1zlrKKv1uh2KMMTErYZJC\nwe6D/POjrXyypcjtUIwxx6iwsJDLL7+cvn37csIJJ3DOOeewceNGx8/77LPPkpmZyYgRI0LT2rVr\n693noYce4sCBA47H1lQSJimM6deBVqlJzP2q0O1QjDHHQFW56KKLGDduHFu2bGH58uX87//+L9u3\nbz9su8rKSkfOP3HiRFauXBmahgwZUu/29SUFvz/2Wi4SJimkJnk5Y3An3lu3nUp/ldvhGGMaaeHC\nhSQnJzN58uRQ2fDhwxk7diyLFi1i7Nix/OxnPwt9WT/44INkZ2eTnZ3NQw89BEBJSQnnnnsuw4cP\nJzs7mxkzZgAwdepUhgwZwrBhw/jd734XcUyLFi1i3LhxXHLJJQwaNIirrroKVeWRRx7hhx9+YPz4\n8YwfPx6AjIwMbr31VoYPH87SpUtZsGABI0eOZOjQofziF7+grKwMCAzpc/vttzN06FBGjx7N5s2b\n2bdvH71796aiogKAvXv3HrbcFBLqltTcLB9vrfyBL/J3c0rfDm6HY0yz95//WsPaH/Y26TGHdG3N\n78/PqnN9Xl4eJ5xwQp3rV6xYQV5eHr1792b58uVMmzaNzz77DFXlpJNO4vTTT+frr7+ma9euvPvu\nuwAUFxdTVFTErFmzWL9+PSLCnj17wh5/xowZfPTRR6HlpUuXAvDll1+yZs0aunbtyqmnnsrHH3/M\nLbfcwoMPPsjChQvp2LEjEEhIJ510Eg888AClpaX079+fBQsWMGDAAK699lqefPJJpkyZAkCbNm34\n6quveP7555kyZQrvvPMO48aN49133+XCCy9k+vTp/PznP2/0MwnhJMyVAsDpAzNJS/Ywb401IRkT\nr0aPHh26R/+jjz7ioosuomXLlmRkZPDzn/+cJUuWMHToUN577z3uuOMOlixZQps2bWjTpg1paWnc\ncMMNvPHGG6Snp4c9fu3moxYtWoTO2717dzweDyNGjCA/Pz/s/l6vl4svvhiADRs20Lt3bwYMGADA\npEmTWLx4cWjbK664IvS3Ovn88pe/ZNq0aQBMmzaN66+//hj/xQ6XUFcK6SlJnD4gk7l5hdx73hA8\nHrutzphjUd8veqdkZWUxc+bMOte3bNmywWMMGDCAFStWMHv2bO6++27OPPNM7r33Xj7//HMWLFjA\nzJkzeeyxx/jggw8ijis1NTU07/V66+zTSEtLw+v1RnTMmreXVs+feuqp5Ofns2jRIvx+P9nZ2RHH\nGImEulIAyM32Ubi3lFUF4S8NjTGx7YwzzqCsrIynn346VLZ69WqWLFlyxLZjx47lzTff5MCBA5SU\nlDBr1izGjh3LDz/8QHp6OldffTW33XYbK1asYP/+/RQXF3POOefw17/+lVWrVjVJvK1atWLfvn1h\n1w0cOJD8/Hw2b94MwAsvvMDpp58eWl/d1zFjxgxOOeWUUPm1117LlVde2eRXCZBgVwoAZwzqTLJX\nmLumkJE927kdjjHmKIkIs2bNYsqUKdx///2kpaXRq1cvHnroIb7//vvDtj3++OO57rrrGD16NBBo\nehk5ciTz5s3jtttuw+PxkJyczJNPPsm+ffu44IILKC0tRVV58MEHw56/dp/CE088UW+8N954I7m5\nuXTt2pWFCxceti4tLY1p06Zx6aWXUllZyYknnnhYB/ru3bsZNmwYqampvPLKK6Hyq666irvvvjvU\nvNSURFWb/KBOGjVqlB7rS3YmPfM53xSVsPB34+zJTGOO0rp16xg8eLDbYcS96heKVXdQ1zRz5kze\neustXnjhhbD7hvuMRGS5qo5q6LwJd6UAgSakO9/4ivWF+xjcpbXb4RhjTMRuvvlm5syZw+zZsx05\nfsL1KQCcPaQzIjA3z+5CMsbEpvz8/LBXCY8++iibN28O3bHU1BIyKXTMSOXEXu3t1lRjjKklIZMC\nwIRsH+sL97F1Z4nboRhjTMxI2KSQk+UDrAnJGGNqStik0LVtC4Z3b8Nca0IyxpiQhE0KADnZPlZ9\nt4cf9hx0OxRjzFHwer2HDV/9pz/9ybFzLVq0iDZt2jBixAgGDRoU0UB5K1eudOzuIKcldFLIDTYh\nWYezMc1LixYtDht/aOrUqUdsU3tY6kiH0g633dixY1m5ciVffvkl77zzDh9//HG9x7Ck0Ez1ycxg\nYOdW1q9gTJzo1asXd9xxB8cffzyvvfYa48aNY8qUKYwaNYqHH36Y/Px8zjjjDIYNG8aZZ57Jt99+\nC8B1113H5MmTOemkk7j99tvrPH6LFi0YMWJE6Mnpzz//nFNOOYWRI0cyZswYNmzYQHl5Offeey8z\nZsxgxIgRzJgxg5KSEn7xi18wevRoRo4cyVtvvRWVf4/GSMiH12rKyfbx2Aeb2Lm/jI4ZqQ3vYIw5\nZM5UKPyqaY/pGwoT6m8OOnjwICNGjAgt33nnnUycOBGADh06sGLFCgCeeuopysvLqR4F4fzzz2fS\npElMmjSJZ555hltuuYU333wTgIKCAj755JN6B6vbvXs3mzZt4rTTTgNg0KBBLFmyhKSkJN5//33u\nuusuXn/9de677z6WLVvGY489BsBdd93FGWecwTPPPMOePXsYPXo0Z511VkSD90VbwieF3CwfjyzY\nxPtrt3P56J5uh2OMiUB181E41ckh3PLSpUt54403ALjmmmsOuyq49NJL60wIS5YsYfjw4WzatIkp\nU6bg8wWanouLi5k0aRKbNm1CROp82c38+fN5++23+ctf/gJAaWkp3377bUwOF5LwSWFwl1Yc1yGd\nOXmFlhSMOVoN/KJ3Q+1f35H+Gq9vu7Fjx/LOO++wdetWTj75ZC677DJGjBjBPffcw/jx45k1axb5\n+fmMGzcu7P6qyuuvv87AgQMjrodbHOtTEJEeIrJQRNaKyBoR+W2YbUREHhGRzSKyWkSOdyqeeuIk\nN8vHJ1t2Unyw6V5pZ4yJPWPGjGH69OkAvPTSS4wdO/ao9u/duzdTp07l/vvvBwJXCt26dQPg2Wef\nDW1Xe7jsnJwcHn30UaoHIP3yyy+PpRqOcrKjuRK4VVWHACcDN4lI7TdcTwD6B6cbgScdjKdOOdk+\nKvzKwvU73Di9MeYoVfcpVE/h7j4K59FHH2XatGkMGzaMF154gYcffviozz158mQWL15Mfn4+t99+\nO3feeScjR4487K6l8ePHs3bt2lBH8z333ENFRQXDhg0jKyuLe+6556jPGy1RGzpbRN4CHlPV92qU\n/Q1YpKqvBJc3AONUdVtdx2mKobNrq6pSxvzpA4b3aMPfrmlwZFljEpoNnR37jmXo7KjckioivYCR\nwGe1VnUDvquxXBAsiyqPR8jJ6syHG3/kQHlk9zIbY0w8cjwpiEgG8DowRVX3NvIYN4rIMhFZ9uOP\nPzZtgEE52T5KK6pYvNGZ4xtjTHPgaFIQkWQCCeElVX0jzCbfAz1qLHcPlh1GVZ9W1VGqOiozM9OR\nWEf3ak+79GR7kM2YCDS3NzYmkmP9bJy8+0iAfwLrVDX8y07hbeDa4F1IJwPF9fUnOCnJ6+GnQ3ws\nWLeDskp/wzsYk6DS0tIoKiqyxBCDVJWioiLS0tIafQwnn1M4FbgG+EpEqp8yuQvoCaCqTwGzgXOA\nzcAB4HoH42lQbraPGcu+45MtRYwf2MnNUIyJWd27d6egoACnmnLNsUlLS6N79+6N3t+xpKCqHwHS\nwDYK3ORUDEdrTL8OZKQmMS+v0JKCMXVITk6md+/ebodhHJLQA+LVlprk5YxBnZi/djv+Krs0NsYk\nHksKtUzI9rGrpJzPt+5yOxRjjIk6Swq1nD4wk9Qkj71jwRiTkCwp1JKeksTpAzKZm1dIlTUhGWMS\njCWFMCYM9VG4t5TV3xe7HYoxxkSVJYUwzhjUmSSPMCfPlUcmjDHGNZYUwmjTIpkx/ToyL6/QHtAx\nxiSUBpOCiPQVkdTg/DgRuUVE2jofmrtys3zkFx1gw/Z9DW9sjDFxIpIrhdcBv4j0A54mMFbRy45G\nFQN+mtUZEZjzld2FZIxJHJEkhSpVrQQuAh5V1duALs6G5b6OGamc2Ku93ZpqjEkokSSFChG5ApgE\nvBMsS3YupNiRm+VjfeE+tu4scTsUY4yJikiSwvXAKcD/qOpWEekNvOBsWLEhJ9sHYFcLxpiE0WBS\nUNW1wB3AiuDyVlW93+nAYkG3ti0Y3r0Nc+wdC8aYBBHJ3UfnAyuBucHlESLyttOBxYqcbB+rvtvD\nD3sOuh2KMcY4LpLmoz8Ao4E9AKq6EujjYEwxJTcr0IQ035qQjDEJIKKOZlWtPd5DlRPBxKI+mRkM\n6JzBXEsKxpgEEElSWCMiVwJeEekvIo8CnzgcV0zJze7C51t3UbS/zO1QjDHGUZEkhZuBLKCMwENr\nxcBvnQwq1uRm+ahSeG/tdrdDMcYYR0WSFM5V1f9Q1ROD093Az5wOLJYM7tKKnu3TrQnJGBP3IkkK\nd0ZYFrdEhAnZPj7evJPigxVuh2OMMY5JqmuFiEwAzgG6icgjNVa1BiqdDizW5GT7+Nvir1m4fgcX\njuzmdjjGGOOI+q4UfgCWAaXA8hrT20CO86HFlhHd29K5dSpz7UE2Y0wcq/NKQVVXAatE5GVVTfg2\nE49HyMny8eqy7zhY7qdFitftkIwxpslF0qfQS0RmishaEfm6enI8shiUm+2jtKKKDzfucDsUY4xx\nRCRJYRrwJIF+hPHA88CLTgYVq0b3ak+79GRrQjLGxK1IkkILVV0AiKp+o6p/AM51NqzYlOT1cPaQ\nzixYt4PyyoR5qNsYk0AiSQplIuIBNonIb0TkIiDD4bhiVm62j31llXyyZafboRhjTJOLJCn8FkgH\nbgFOAK4m8MKdhHRqv45kpCZZE5IxJi7VmxRExAtMVNX9qlqgqter6sWq+mmU4os5qUlezhjUiflr\nt+OvUrfDMcaYJlVvUlBVP/CTKMXSbORm+9hVUs4X+bvcDsUYY5pUnc8p1PBl8KU6rwGhlxWr6huO\nRRXjTh+QSWqSh7l5hZzcp4Pb4RhjTJOJpE8hDSgCzgDOD07nORlUrGuZmsTpAzKZt6aQKmtCMsbE\nkQavFFT1+mgE0tzkZvuYv3Y7q78vZkSPtm6HY4wxTSKSKwUTxpmDOpPkEbsLyRgTVxxLCiLyjIjs\nEJG8OtaPE5FiEVkZnO51KhYntElPZky/jszN24aqNSEZY+JDQ7ekekTkskYe+1kgt4FtlqjqiOB0\nXyPP45rcLB/5RQfYsH2f26EYY0yTaOiW1Crg9sYcWFUXA3F9z+bZQzojgjUhGWPiRiTNR++LyO9E\npIeItK+emuj8Y0RktYjMEZGsJjpm1GS2SuXE49pbUjDGxI1IksJE4CZgMYdetLOsCc69AuipqsOA\nR4E369pQRG4UkWUisuzHH39sglM3ndxsH+sL95G/s6ThjY0xJsY1mBRUtXeYqc+xnlhV96rq/uD8\nbCBZRDrWse3TqjpKVUdlZmYe66mbVE62D4C5a+xqwRjT/DWYFEQkWURuCb5oZ2ZwpNTkYz2xiPhE\nRILzo4OxFB3rcaOtW9sWDOvexpqQjDFxIZLmoycJjI76RHA6IVhWLxF5BVgKDBSRAhG5QUQmi8jk\n4CaXAHkisgp4BLhcm+m9nTlZPlZ+t4dtxQfdDsUYY45JJGMfnaiqw2ssfxD8Iq+Xql7RwPrHgMci\nOH/Mm5Dt48/zNjAvr5DrTu3tdjjGGNNokVwp+EWkb/WCiPQB/M6F1Pz0ycxgQOcM61cwxjR7kVwp\n3AYsFJGvAQGOA2w8pFpys3w8tnAzRfvL6JCR6nY4xhjTKA0+0QwcBPoTePPazcBAVV0YhdialZxs\nH1UK763d7nYoxhjTaJE80fy4qpap6urgVBal2JqVIV1a07N9ujUhGWOatUj6FBaIyMXVt4+a8ESE\n3GwfH2/eyd7SCrfDMcaYRokkKfyawFvXykRkr4jsE5G9DsfVLOVk+ajwKwvX73A7FGOMaZSG+hQE\nyFJVj6qmqGprVW2lqq2jFF+zMrJHWzq3TmXOV9aEZIxpnhrqU1Dg3SjF0ux5PEJOlo9FG3dwsNzu\n2jXGND+RNB+tEJETHY8kTuRm+SitqOLDjbE1cJ8xxkQikqRwErBURLYEh7n+SkRWOx1YczW6d3va\npSczz+5CMsY0Q5E8vJbjeBRxJMnr4ewhnZmTV0h5ZRUpSfYabGNM81HnN5aInAGgqt8AHlX9pnoi\nMCieqUNuto99pZV8smWn26EYY8xRqe9n7F9qzL9ea93dDsQSN8b07UhGapI1IRljmp36koLUMR9u\n2dSQluxl/KBOzF+zHX9VsxwN3BiToOpLClrHfLhlU8uEbB9FJeV8kb/L7VCMMSZi9XU09xGRtwlc\nFVTPE1y2lwY04PQBmaQmeZibV8jJfTq4HY4xxkSkvqRwQY35v9RaV3vZ1NIyNYnTBmQyb00hvz9/\nCDZ0lDGmOagvKVwFzAHeV9V9UYonruRm+Xhv7XZWFRQzokdbt8MxxpgG1den8E9gODBbRBaIyB0i\nMrye7U0tZw3uTJJHmJtndyEZY5qHOpOCqn6mqn9Q1bHAZcC3wK0i8qWIPCMil0UtymaqTXoyp/Tt\nwNy8bQSGkTLGmNjW4OO2IuJV1SJVfUVVr1XVkcDjBN7GZhqQm+0jv+gAG7fvdzsUY4xpUCRjMGwS\nkT+LyJDqAlVdrqr/42BcceOnQ3yIwJy8bW6HYowxDYokKQwHNgL/EJFPReRGEbH3KUQos1UqJx7X\n3voVjDHNQoNJQVX3qerfVXUMcAfwe2CbiDwnIv0cjzAO5GT7WF+4j/ydJW6HYowx9YqoT0FEfiYi\ns4CHgAeAPsC/gNkOxxcXcrI6A9hYSMaYmBdRnwKBB9n+rKojVfVBVd2uqjOBuc6GFx+6t0tnWPc2\nzLEmJGNMjIskKQxT1RtU9ZPaK1T1Fgdiiks5WT5WfreHbcUH3Q7FGGPqFElS6CQi/xKRnSKyQ0Te\nEpE+jkcWZ3KzfQDMX7Pd5UiMMaZukSSFl4FXAR/QFXgNeMXJoOJR38wM+nfKsFtTjTExLZKkkK6q\nL6hqZXB6EUhzOrB4NCHbx+dbd1G0v8ztUIwxJqxIksIcEZkqIr1E5DgRuZ3AeEjtRaS90wHGk5xs\nH1UK76+zJiRjTGyqb5TUatVjHP26VvnlBF62Y/0LERrSpTU92rdgbl4hE0/s6XY4xhhzhAaTgqra\nC3WaiIiQm+Xj2U/y2VtaQeu0ZLdDMsaYw0Ty8FqyiNwiIjOD029ExL7NGik3uwsVfmXh+h1uh2KM\nMUeIpE/hSeAE4IngdEKwzDTCyB5t6dQq1cZCMsbEpEj6FE5U1Zov1/lARFY1tJOIPAOcB+xQ1eww\n6wV4GDgHOABcp6orIgu7+fJ4hJwsHzOXF3Cw3E+LFK/bIRljTEgkVwp+EelbvRB8cM0fwX7PArn1\nrJ9A4J0M/YEbSaCrjwnZPg5W+Plw449uh2KMMYeJJCncBiwUkUUi8iHwAXBrQzup6mJgVz2bXAA8\nrwGfAm1FpEskQTd3o3u3p216sg2QZ4yJOfU2H4mIBzhI4Nf8wGDxBlVtiqevugHf1VguCJYd8civ\niNxI4GqCnj2b/62cSV4PZw/uzNw1hZRXVpGSFEluNsYY59X7baSqVcDjqlqmqquDU9Qfx1XVp1V1\nlKqOyszMjPbpHZGb7WNfaSWfbNnpdijGGBMSyU/UBSJycbBjuCl9D/Sosdw9WJYQTu3XkYzUJGtC\nMsbElEiSwq8JDIJXJiJ7RWSfiOxtgnO/DVwrAScDxaqaMKPFpSV7GT+oE/PXbMdfpW6HY4wxQGSv\n42ylqh5VTVHV1sHlBt/RLCKvAEuBgSJSICI3iMhkEZkc3GQ28DWwGfg78O/HUI9mKTfLR1FJOcvy\n6+uPN8aY6GnwOQURWaCqZzZUVpuqXtHAegVuiijKODVuYCapSR7m5BVyUp8ObodjjDF1XymISFpw\nFNSOItKuelRUEelF4C4hc4xapiZx2oBM5q0pJJAjjTHGXfU1H/0aWA4MCv6tnt4CHnM+tMSQm+Vj\nW3EpqwuK3Q7FGGPqTgqq+nBwhNTfqWofVe0dnIarqiWFJnLm4E4keYS5dheSMSYGRDJ09qMiMgbo\nVXN7VX3ewbgSRtv0FE7p24G5eYXcnjOQpr/z1xhjIhfJ0NkvAH8BfgKcGJxGORxXQsnN9rF1Zwkb\nt+93OxRjTIKLZJTUUcAQtZ5Qx5w9pDN3v5nH3LxCBvpauR2OMSaBRfLwWh7gczqQRNapVRqjjmtn\n/QrGGNdFkhQ6AmtFZJ6IvF09OR2YI4q2uB1BnXKzu7Bu216+KSpxOxRjTAKLJCn8AbgQ+CPwQI2p\neVk1HR4fDVs+cDuSsHKyOgPYG9mMMa6q7+G1QQCq+iHwqap+WD0BUR8p9ZgNPAc6DoQZ10JhntvR\nHKF7u3SGdmtjTUjGGFfVd6Xwco35pbXWPeFALM5Kaw1XvQapGfDyZbD3B7cjOkJuto8vv93DtuKD\nbodijElQ9SUFqWM+3HLz0KYbXPkqlBbDS5dB2T63IzpMbnagP3/+mu0uR2KMSVT1JQWtYz7ccvPR\nZRhc9hzsWAuvXQf+CrcjCumbmUH/ThnWr2CMcU19SaG7iDwiIo/WmK9ebt4D4vU7C877K2x+H969\nFWLoEYzcbB+fbS1iV0m526EYYxJQfQ+v3VZjflmtdbWXm58TJsGeb2DJA9DuOBh7q9sRAZCT5ePR\nDzbz3tpCJp7Y/N9HbYxpXupMCqr6XDQDccX4u2H3N7DgPmh7HAy9xO2IyOramh7tWzA3z5KCMSb6\nInlOIX55PHDhE3DcqfDmv0H+x25HhIiQm+Xj481F7C2Nnf4OY0xiSOykAJCUChNfDFwpTL8Sftzo\ndkTkZvso91excP0Ot0MxxiQYSwoA6e3h6pngTYaXLoH97n4Zj+zRjk6tUu0uJGNM1EUydPb/iUhr\nEUkWkQUi8qOIXB2N4KKqXS+4YkYgIbxyOZQfcC0Uj0fIyfKxaMOPHCz3uxaHMSbxRHKl8FNV3Quc\nB+QD/Tj8zqT40f0EuOSf8P0KeONXUOXeF3Juto+DFX4Wb/rRtRiMMYknkqRQfYfSucBrqhrfLxMe\ndC7k/gnWvwPz/sO1MEb3bk/b9GRrQjLGRFUkL9l5R0TWAweBfxORTKDU2bBcdvLkwDMMnz4ReIbh\n5H+LegjJXg9nD+7M3DWFlFdWkZJk3T/GGOc1+E2jqlOBMcAoVa0ASoALnA7MdT/9bxh0Hsy9E9b9\ny5UQcrN97CutZOnXRa6c3xiTeCLpaL4UqFBVv4jcDbwIdHU8Mrd5vPDzv0O3E+D1X0FB9B/iPrVf\nR1qmeK0JyRgTNZG0SdyjqvtE5CfAWcA/gSedDStGpKTDFdOhVWd4eSLs2hrV06clexk/qBPvrS3E\nXxU74zMZY+JXJEmh+hacc4GnVfVdIMW5kGJMRiZcNRPUDy9dCgd2RfX0E7K7sHN/Ocvyo3teY0xi\niiQpfC8ifwMmArNFJDXC/eJHx/5w+cuBzufpV0FF9PrZxw3MJCXJY29kM8ZERSRf7pcB84AcVd0D\ntCden1Ooz3Fj4MIn4dtP4K1/h6qqqJy2ZWoSp/XPZF5eIRpDQ3wbY+JTJHcfHQC2ADki8hugk6rO\ndzyyWDT0Ejjz95D3OnzwX1E7bW62jx+KS1ldEN+PiBhj3BfJ3Ue/BV4COgWnF0XkZqcDi1k/+X9w\nwnXw0YOwbFpUTnnW4E4kecSakIwxjouk+egG4CRVvVdV7wVOBn7lbFgxTATOeSDw9rZ3b4VN7zl+\nyrbpKZzStwNzrQnJGOOwSJKCcOgOJILz4kw4zYQ3CS59FjoPCbznedtqx0+Zk+Vj684SNm7f7/i5\njDGJK5KkMA34TET+ICJ/AD4l8KxCYkttBVe+Bmlt4OXLoLjA0dP9NKszItiDbMYYR0XS0fwgcD2w\nKzhdr6oPRXJwEckVkQ0isllEpoZZP05EikVkZXC692gr4KrWXeCq16C8BF66DEqd6wju1CqNUce1\ns34FY4yj6k0KIuIVkfWqukJVHwlOX0ZyYBHxAo8DE4AhwBUiMiTMpktUdURwuu+oa+C2zllw2fOw\ncwO8Ogn8zr1CMyfLx7pte/mmqMSxcxhjElu9SUFV/cAGEWnMG+RHA5tV9WtVLQemE68D6fUdD+c/\nDF8vhH9NAYc6g3OyfIA1IRljnBNJn0I7YE3wrWtvV08R7NcN+K7GckGwrLYxIrJaROaISFYEx41N\nI6+G026HlS/C4r84cooe7dMZ2q2NNSEZYxwTyfsU7nHw/CuAnqq6X0TOAd4E+tfeSERuBG4E6Nmz\nMRctUTL+LtjzLSz8b2jbE4ZPbPJT5Gb7+PO8DRQWl+Jrk9bkxzfGJLY6rxREpJ+InKqqH9acCNyS\nGsmtNt8DPWosdw+WhajqXlXdH5yfDSSLSMfaB1LVp1V1lKqOyszMjODULhGBnz0KvcbCWzfB1sVN\nforqJqSnNsPTAAAP/UlEQVT5a+1qwRjT9OprPnoI2BumvDi4riFfAP1FpLeIpACXA4c1O4mIT0Qk\nOD86GE/zfqNMUgpMfBE69IXpV8OO9U16+H6dMujXKYM5X1lSMMY0vfqSQmdV/ap2YbCsV0MHVtVK\n4DcEBtNbB7yqqmtEZLKITA5udgmQJyKrgEeAyzUeHtlt0RaufBWSUgPDbe/b3qSHn5Dt47OtRewq\nKW/S4xpjTH1JoW0961pEcnBVna2qA1S1r6r+T7DsKVV9Kjj/mKpmqepwVT1ZVT+JPPQY1+44uHIG\nHNgZeLitvOluI83J8lGl8P7apk02xhhTX1JYJiJHjHEkIr8EljsXUhzpdjxcMg0KV8PMG6DK3/A+\nEcjq2pru7VrYXUjGmCZXX1KYAlwvIotE5IHg9CGBAfJ+G53w4sDAXJjwf7BxDsy5o0meYRARcrN8\nfLRpJ/tKnXtYzhiTeOpMCqq6XVXHAP8J5Aen/1TVU1TVfqIejdG/gjE3wxd/h6WPN8khJwz1Ue6v\n4oP1O5rkeMYYAxE8p6CqC4GFUYglvp11X+AZhvl3Q9seMOTYHu4e2aMdma1SmbemkAtGhHsm0Bhj\njl5ivWvZTR4PXPQ36H4ivHEjfPf5MR5OyMnqzML1P3KwvGn6KowxxpJCNCW3gCumQ+uu8MrlULTl\nmA6Xm9WFgxV+Fm/6sYkCNMYkOksK0dayA1w1M9Dh/NIlUNL4Z/VO6tOetunJzLMB8owxTcSSghs6\n9A1cMRR/D9OvgIrSRh0m2evhrMGdeX/ddsorq5o4SGNMIrKk4JaeJ8HP/wbffQazfg1VjftSz83y\nsbe0kqVfN+/RQYwxscGSgpuyLoKz/wvWvgnv/75Rh/hJ/460TPHaOxaMMU3CkoLbxtwMJ/4SPnkE\nvvjHUe+eluxl/KBOvLe2EH9V8x82yhjjLksKbhOB3PthQC7Mvg02zjvqQ+Rm+9i5v5zl3+x2IEBj\nTCKxpBALvElw8T/BNxReux5+iOg12CHjBnYiJcnDnLxtDgVojEkUlhRiRWpGYLjt9Pbw8sTA088R\nykhN4rT+mczLKyQeRh43xrjHkkIsaeWDq14L3KL60qVwcE/Eu+Zm+/ihuJSvvi92MEBjTLyzpBBr\nOg2GiS8EnnZ+9RqojOxFOmcN7oTXI8yxu5CMMcfAkkIs6nN64F3PWxfDv26JaLjttukpnNKnA3Ot\nCckYcwwsKcSqEVfAuLtg1Suw6E8R7ZKb7WPrzhI27djvcHDGmHhlSSGWnX47jLgKPvwTfPlSg5v/\ndEhnRLAH2YwxjWZJIZaJwPkPQ59xgWakLfW/1qJT6zRO6NnO+hWMMY1mSSHWeZPhsueh4wB49VrY\nvrbezXOzfazbtpdvikqiFKAxJp5YUmgO0toEblVNTg/cqrq37ofUcrJ8AMxbY1cLxpijZ0mhuWjT\nHa56FUr3wMuXQVn4zuQe7dPJ7tba+hWMMY1iSaE56TIcLn0Wtq+BmdeDvzLsZrlZPlZ8u4fC4sa9\np8EYk7gsKTQ3/c+Gcx+ATfNhzm1hn2HIze4CwPy1drVgjDk6lhSao1HXw6lTYNkz8PHDR6zu1ymD\nfp0yrAnJGHPULCk0V2f+HrIvDrycJ+/1I1bnZvn4bOsudpVENkyGMcaAJYXmy+OBC56AnqfArMnw\nzdLDVudm+/BXKe+v3e5SgMaY5siSQnOWnAaXvwxte8L0K2DnptCqrK6t6d6uBbPztlFlb2QzxkRI\nmtvgaaNGjdJly5a5HUZs2fU1/OPswDsZfrkAWnYE4L/fWcs/PtqKR6BdegrtWqbQPj2Fdi2Tad8y\nhXbpKYf/rbE+IzUJEXG5YsaYpiIiy1V1VEPbJUUjGOOw9n3giunw3HnwyuUw6V+Q3IKbxveje7sW\nFJWUs6uknN0HAn/zdx5gxbd72F1STmUdVxHJXgmTNJKDSSN8MmmR4o1yxY0xTc2uFOLJun/BjGtg\n8Hlw6XPgqf9LWlXZV1bJ7sOSRkVg+UB5rfJydh+oYPeB8jpH8k5N8oRJFslHJpEaSSY1yRKJMdFg\nVwqJaPD5kPNHmHcnzL8Hcv9Y7+YiQuu0ZFqnJXNch5YRncJfpew9WBEmaVQcSh7BpFKw+wC7SsrZ\nWxr+ITuAlineOpJGco3mrEPl7dKTSfJaV5gxTrGkEG9O+XfY8w18+ji0Ow5O+nWTHt7rEdoFrwLI\njGyfCn8Vew4cmTQCSaVG+YFytvy4n90l5ZSU++s8Xuu0pFp9IIcnk9ZpyaQle0lJ8pCa5CE1yUtq\ncmA+pXo5uM4SjDGHczQpiEgu8DDgBf6hqn+qtV6C688BDgDXqeoKJ2NKCDl/hD3fwdyp0DITep8W\nGG3VmxKYGmhWamrJXg+ZrVLJbJUa8T6lFX72HKio1XxVM6kEmrm2FZeydtteikrKKa+sOurYvB4h\nxesJJY3qhBE+oRxKJvUlmtRkb9hj1t4vNSmQuLwe69A3scOxpCAiXuBx4GygAPhCRN5W1ZpjP08A\n+genk4Ang3/NsfB44eJ/wLPnBsZIOoIcShA1k0VoPlxZY7dNPsrjBebTvCn4WqXga5MWUZVVlYMV\n/kBz1cFKyv1VlFX4KausCk5+yqvna5SXB9cFyoPb+avnA8slJZV17lvuP/pEVFuSR0LJ5IiElBRI\nLine8Amlej45SfCK4PUEpiSP4Kn+K0KSN/DXG6YsyePB44EkjwevB7wez2HHCk0ieL0Sdl3omMHz\nmubLySuF0cBmVf0aQESmAxcANZPCBcDzGujt/lRE2opIF1Wte2xoE5mUdLhmFqx/ByoOgr88OFXU\nM19xZHllGZTta2C/cqiqcKYe4okoEYk3hXRPEunVZeIJTB5vcN5bY75WuXgg1QtpR7mPx0sVHvwq\nVKhQWQUV6qFShYoqqFChwh9YV14VKCuvEsqrCMz7hXK/UFYFZX6oqBLK/EqZH8r8Qqkfyqug9GBg\nfWmlstsvlPuVg5XCwUqltFIprxKU6gk4bJ7D1lXPE2ZduG2hcV/wNZOSV2okqFpJKWzy8dRRXqvM\nI4JHAn1jIiBUL4OnukwE4dCyJ3ib9aHlevbn0Lrq5eqEd9j+HDpXYDmw3ZHnDrNt2JjqOjf0bN+S\nfp0yGvWZRPzZOXjsbsB3NZYLOPIqINw23QBLCk2hRVsYeXV0zqXacOKomUDClR/TfAVUlkLZ3sDo\nsVoF6ocq/6F5rYKqmvM11lVVhd+nAZ7glOz4P3AdJ0+J3ulCCSX0/MrhSai6vGZCqU5ACqCC+iX4\nz1pz37qS0+FJTLV2ORx2I5we2pfa68JseyhOPWI7RY44QF33adZMspGUR7ptuLJvel1Cv1/cF/Fx\nG6NZdDSLyI3AjQA9e/Z0ORoTlggkpQSmeKIaTBINJJLQuqNIPmH3CZOYqvzBb8Rw+1SvqyLwTac1\n/hKmTA/V64iycNsfKhMUOarjUk8cRxtbdRm1jnHEB1b359iIbUORBs9f8zAa3FaDW4WqXF2uh45w\naNsa1ajeU+s67qGDVq/uOHBA+JibkJNJ4XugR43l7sGyo90GVX0aeBoCzyk0bZjG1EMEvEk0k99P\npolJrb+JwMn78b4A+otIbxFJAS4H3q61zdvAtRJwMlBs/QnGGOMex37+qGqliPwGmEfgltRnVHWN\niEwOrn8KmE3gdtTNBG5JDXerjDHGmChx9JpYVWcT+OKvWfZUjXkFbnIyBmOMMZGzxzmNMcaEWFIw\nxhgTYknBGGNMiCUFY4wxIZYUjDHGhDS7l+yIyI/AN43cvSOwswnDaQ6szonB6pwYjqXOx6lqgwPe\nN7ukcCxEZFkkbx6KJ1bnxGB1TgzRqLM1HxljjAmxpGCMMSYk0ZLC024H4AKrc2KwOicGx+ucUH0K\nxhhj6pdoVwrGGGPqkTBJQURyRWSDiGwWkalux+MUEckXka9EZKWILAuWtReR90RkU/BvO7fjPBYi\n8oyI7BCRvBplddZRRO4Mfu4bRCTHnaiPTR11/oOIfB/8rFeKyDk11jXrOotIDxFZKCJrRWSNiPw2\nWB63n3M9dY7u56yqcT8RGLp7C9CHwAsMVwFD3I7LobrmAx1rlf0fMDU4PxW43+04j7GOpwHHA3kN\n1REYEvy8U4Hewf8OvG7XoYnq/Afgd2G2bfZ1BroAxwfnWwEbg/WK28+5njpH9XNOlCuF0cBmVf1a\nVcuB6cAFLscUTRcAzwXnnwMudDGWY6aqi4FdtYrrquMFwHRVLVPVrQTe3TE6KoE2oTrqXJdmX2dV\n3aaqK4Lz+4B1BN7fHrefcz11rosjdU6UpNAN+K7GcgH1/2M3Zwq8LyLLg++2Buish95oVwh0dic0\nR9VVx3j/7G8WkdXB5qXqppS4qrOI9AJGAp+RIJ9zrTpDFD/nREkKieQnqjoCmADcJCKn1VypgevO\nuL7lLBHqGPQkgSbREcA24AF3w2l6IpIBvA5MUdW9NdfF6+ccps5R/ZwTJSl8D/Sosdw9WBZ3VPX7\n4N8dwCwCl5PbRaQLQPDvDvcidExddYzbz15Vt6uqX1WrgL9zqOkgLuosIskEvhxfUtU3gsVx/TmH\nq3O0P+dESQpfAP1FpLeIpACXA2+7HFOTE5GWItKqeh74KZBHoK6TgptNAt5yJ0JH1VXHt4HLRSRV\nRHoD/YHPXYivyVV/OQZdROCzhjios4gI8E9gnao+WGNV3H7OddU56p+z2z3uUezZP4dAb/4W4D/c\njsehOvYhcDfCKmBNdT2BDsACYBPwPtDe7ViPsZ6vELiMriDQjnpDfXUE/iP4uW8AJrgdfxPW+QXg\nK2B18AuiS7zUGfgJgaah1cDK4HROPH/O9dQ5qp+zPdFsjDEmJFGaj4wxxkTAkoIxxpgQSwrGGGNC\nLCkYY4wJsaRgjDEmxJKCMVEkIuNE5B234zCmLpYUjDHGhFhSMCYMEblaRD4Pjl//NxHxish+Eflr\ncKz7BSKSGdx2hIh8GhywbFb1gGUi0k9E3heRVSKyQkT6Bg+fISIzRWS9iLwUfJLVmJhgScGYWkRk\nMDAROFUDgwv6gauAlsAyVc0CPgR+H9zleeAOVR1G4MnT6vKXgMdVdTgwhsATyRAY/XIKgfHw+wCn\nOl4pYyKU5HYAxsSgM4ETgC+CP+JbEBh4rQqYEdzmReANEWkDtFXVD4PlzwGvBceg6qaqswBUtRQg\neLzPVbUguLwS6AV85Hy1jGmYJQVjjiTAc6p652GFIvfU2q6xY8SU1Zj3Y/8fmhhizUfGHGkBcImI\ndILQe4GPI/D/yyXBba4EPlLVYmC3iIwNll8DfKiBN2cViMiFwWOkikh6VGthTCPYLxRjalHVtSJy\nNzBfRDwERia9CSgBRgfX7SDQ7wCBIZyfCn7pfw1cHyy/BvibiNwXPMalUayGMY1io6QaEyER2a+q\nGW7HYYyTrPnIGGNMiF0pGGOMCbErBWOMMSGWFIwxxoRYUjDGGBNiScEYY0yIJQVjjDEhlhSMMcaE\n/H8YOEeX73Uq9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc7897d1550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 请绘制上面训练过程的损失函数曲线，以及'''错误率曲线'''！！！\n",
    "plt.plot(np.arange(len(train_losses))*50, train_losses, label = 'Cross Entropy')\n",
    "plt.plot(np.arange(len(train_losses))*50, np.array(train_errors) / 100.0, label = 'Error Rate')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Cross Entropy/Error rates')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四步：在测试集上测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一个专门计算分类错误率的函数，它的基本思想是，对于预测向量predictions的每一行，\n",
    "# 取最大的那个元素的下标，与标签labels中的元素做比较\n",
    "#def error_rate(predictions, labels):\n",
    "#    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，labels是数据之中的正确答案\"\"\"\n",
    "#    predictions = np.argmax(predictions, 1)\n",
    "#    return 100.0 - (\n",
    "#      100.0 *\n",
    "#      np.sum( predictions == labels) /\n",
    "#      predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age:1\tER:2.0900000000000034\n",
      "Age:2\tER:2.1111111111111143\n",
      "Age:3\tER:2.102040816326536\n",
      "Age:4\tER:2.1030927835051614\n",
      "Age:5\tER:2.09375\n",
      "Age:6\tER:2.094736842105263\n",
      "Age:7\tER:2.1063829787234027\n",
      "Age:8\tER:2.0967741935483843\n",
      "Age:9\tER:2.108695652173907\n",
      "Age:10\tER:2.120879120879124\n",
      "Age:11\tER:2.0888888888888886\n",
      "Age:12\tER:2.089887640449433\n",
      "Age:13\tER:2.068181818181813\n",
      "Age:14\tER:2.0344827586206833\n",
      "Age:15\tER:2.0116279069767415\n",
      "Age:16\tER:2.023529411764713\n",
      "Age:17\tER:1.9642857142857082\n",
      "Age:18\tER:1.9518072289156692\n",
      "Age:19\tER:1.9268292682926784\n",
      "Age:20\tER:1.9506172839506206\n",
      "Age:21\tER:1.9124999999999943\n",
      "Age:22\tER:1.8227848101265778\n",
      "Age:23\tER:1.8205128205128176\n",
      "Age:24\tER:1.818181818181813\n",
      "Age:25\tER:1.7894736842105203\n",
      "Age:26\tER:1.7199999999999989\n",
      "Age:27\tER:1.7297297297297263\n",
      "Age:28\tER:1.657534246575338\n",
      "Age:29\tER:1.625\n",
      "Age:30\tER:1.6197183098591523\n",
      "Age:31\tER:1.5714285714285694\n",
      "Age:32\tER:1.5652173913043441\n",
      "Age:33\tER:1.57352941176471\n",
      "Age:34\tER:1.5820895522388128\n",
      "Age:35\tER:1.606060606060609\n",
      "Age:36\tER:1.6153846153846132\n",
      "Age:37\tER:1.515625\n",
      "Age:38\tER:1.5238095238095184\n",
      "Age:39\tER:1.4354838709677438\n",
      "Age:40\tER:1.3934426229508148\n",
      "Age:41\tER:1.3499999999999943\n",
      "Age:42\tER:1.3220338983050794\n",
      "Age:43\tER:1.3103448275862064\n",
      "Age:44\tER:1.2807017543859587\n",
      "Age:45\tER:1.2857142857142918\n",
      "Age:46\tER:1.2363636363636346\n",
      "Age:47\tER:1.1851851851851904\n",
      "Age:48\tER:1.1886792452830122\n",
      "Age:49\tER:1.1538461538461604\n",
      "Age:50\tER:1.0980392156862706\n",
      "Age:51\tER:1.0799999999999983\n",
      "Age:52\tER:1.1020408163265358\n",
      "Age:53\tER:1.1041666666666714\n",
      "Age:54\tER:1.1276595744680833\n",
      "Age:55\tER:1.1304347826087024\n",
      "Age:56\tER:1.13333333333334\n",
      "Age:57\tER:1.1590909090909065\n",
      "Age:58\tER:1.139534883720927\n",
      "Age:59\tER:1.1428571428571388\n",
      "Age:60\tER:1.146341463414629\n",
      "Age:61\tER:1.0750000000000028\n",
      "Age:62\tER:1.0769230769230802\n",
      "Age:63\tER:1.0789473684210549\n",
      "Age:64\tER:1.1081081081081123\n",
      "Age:65\tER:1.1388888888888857\n",
      "Age:66\tER:1.1428571428571388\n",
      "Age:67\tER:0.941176470588232\n",
      "Age:68\tER:0.8484848484848442\n",
      "Age:69\tER:0.84375\n",
      "Age:70\tER:0.8709677419354875\n",
      "Age:71\tER:0.9000000000000057\n",
      "Age:72\tER:0.9310344827586192\n",
      "Age:73\tER:0.9642857142857082\n",
      "Age:74\tER:0.9259259259259238\n",
      "Age:75\tER:0.961538461538467\n",
      "Age:76\tER:0.9599999999999937\n",
      "Age:77\tER:1.0\n",
      "Age:78\tER:1.0434782608695627\n",
      "Age:79\tER:1.0909090909090935\n",
      "Age:80\tER:1.1428571428571388\n",
      "Age:81\tER:1.2000000000000028\n",
      "Age:82\tER:1.2105263157894797\n",
      "Age:83\tER:1.2777777777777715\n",
      "Age:84\tER:1.294117647058826\n",
      "Age:85\tER:1.3125\n",
      "Age:86\tER:1.2666666666666657\n",
      "Age:87\tER:1.2857142857142918\n",
      "Age:88\tER:1.3846153846153868\n",
      "Age:89\tER:1.5\n",
      "Age:90\tER:1.6363636363636402\n",
      "Age:91\tER:1.7999999999999972\n",
      "Age:92\tER:1.5555555555555571\n",
      "Age:93\tER:1.75\n",
      "Age:94\tER:1.8571428571428612\n",
      "Age:95\tER:2.1666666666666714\n",
      "Age:96\tER:2.5999999999999943\n",
      "Age:97\tER:2.75\n",
      "Age:98\tER:3.0\n",
      "Age:99\tER:2.0\n",
      "Age:100\tER:1.0\n",
      "平均错误率：1.5160%\n"
     ]
    }
   ],
   "source": [
    "# 分多个batch计算测试结果\n",
    "test_errors = []\n",
    "test_losses = []\n",
    "i = 0\n",
    "test_batch_size=100\n",
    "\n",
    "for start in range(0, len(test_X), test_batch_size):\n",
    "    \n",
    "    end1 = start + test_batch_size if start + test_batch_size < len(test_X) else len(test_X)\n",
    "    i += 1\n",
    "    if CAN_GPU:\n",
    "        x = Variable(torch.FloatTensor(test_X[start:end])).cuda()\n",
    "        y = Variable(torch.LongTensor(test_Y[start:end])).cuda()\n",
    "    else:\n",
    "        x = Variable(torch.FloatTensor(test_X[start:end]))\n",
    "        y = Variable(torch.LongTensor(test_Y[start:end]))\n",
    "        \n",
    "    predictions = net(x)\n",
    "    \n",
    "    \n",
    "    loss = cost(predictions, y)\n",
    "    if CAN_GPU:\n",
    "        test_losses.append(loss.data.cpu().numpy())\n",
    "        test_errors.append(error_rate(predictions.data.cpu().numpy(), y.data.cpu().numpy()))\n",
    "    else:\n",
    "        test_losses.append(loss.data.numpy())\n",
    "        test_errors.append(error_rate(predictions.data.numpy(), y.data.numpy()))\n",
    "    \n",
    "    \n",
    "    print(\"Age:{0}\\tER:{1}\".format(i, test_errors[-1]))\n",
    "\n",
    "print('平均错误率：%.4f%%'%np.mean(test_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用单个图像进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#随便从数据集中读入一张图片，并绘制出来\n",
    "#idx = 100\n",
    "#muteimg = test_data[idx, 0, :, :]\n",
    "#plt.imshow(muteimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算识别结果\n",
    "#x = Variable(torch.FloatTensor(test_X[idx, :].reshape(1, -1)))\n",
    "#predict = net(x)\n",
    "#np.argmax(predict.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 升级版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果你已经运行跑通上面的所有代码，那么请你尝试对其进行更改，让测试集上面的识别错误率进一步下降，看看能不能到1%以下\n",
    "\n",
    "提示：可以考虑增加层的深度\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数测试与总结\n",
    "\n",
    "* 两层linear(150,50) -> 2.0131%\n",
    "* 两层linear(80,40)  -> 2.3602%\n",
    "* 两层linear(100,30)  -> 1.9346%   测试集错误率在每一个batch上表现稳定\n",
    "* 两层linear(120,30)  -> 1.5356%   错误率下降明显\n",
    "* 两层linear(128,32)  -> 1.6536%   错误率下降明显，不到300次迭代两次监测错误率降低小于0.0005\n",
    "* 三层linear(128,32,16)  -> 2.2962%   与两层区别不明显\n",
    "* 两层linear(150,30)  -> 1.4601%   训练集错误率0.02%\n",
    "* 去掉最后一层的sigmoid之后训练速度明显增快，而且错误率下降明显\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
